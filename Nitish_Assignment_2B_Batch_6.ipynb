{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising input and Output Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "[[1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [0 1 0 1]]\n",
      "Expected output\n",
      "[[1]\n",
      " [1]\n",
      " [0]]\n",
      "Learning rate\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=np.array([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "y=np.array([[1],[1],[0]])\n",
    "lr=0.1\n",
    "print(\"Input\")\n",
    "print(x)\n",
    "\n",
    "print(\"Expected output\")\n",
    "print(y)\n",
    "\n",
    "print(\"Learning rate\")\n",
    "print (lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising random values for Weight and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight at hidden layer\n",
      "[[ 0.55757857  0.53705154  0.17444553]\n",
      " [ 0.1094706   0.96630393  0.50660854]\n",
      " [ 0.20286468  0.56018757  0.13061052]\n",
      " [ 0.70976841  0.77847709  0.7014725 ]]\n",
      "Bias at hidden layer\n",
      "[[ 0.48498012  0.81467324  0.03066518]]\n",
      "Weight at output layer\n",
      "[[ 0.91422133]\n",
      " [ 0.95832739]\n",
      " [ 0.34122907]]\n",
      "Bias at output layer\n",
      "[[ 0.99358184]]\n"
     ]
    }
   ],
   "source": [
    "wh = np.random.random((4,3))\n",
    "bh = np.random.random((1,3))\n",
    "wout=np.random.random((3,1))\n",
    "bout=np.random.random((1,1))\n",
    "\n",
    "print(\"Weight at hidden layer\")\n",
    "print(wh)\n",
    "print(\"Bias at hidden layer\")\n",
    "print(bh)\n",
    "print(\"Weight at output layer\")\n",
    "print(wout)\n",
    "print(\"Bias at output layer\")\n",
    "print(bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate hidden layer input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer input\n",
      "[[ 1.73783775  2.21893273  1.97140658]\n",
      " [ 2.390764    2.2548835   2.19127344]\n",
      " [ 0.86552241  1.49335235  1.20500313]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_input = np.dot(x,wh) + bh\n",
    "\n",
    "print(\"Hidden layer input\")\n",
    "print(hidden_layer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform non-linear transformation on hidden linear input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer activations\n",
      "[[ 0.85041221  0.90193684  0.87776211]\n",
      " [ 0.9161203   0.90507094  0.89946312]\n",
      " [ 0.70381315  0.81658091  0.76941362]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x,derivative=False):\n",
    "    return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "    \n",
    "\n",
    "hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "print(\"Hidden layer activations\")\n",
    "print(hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform linear and non-linear transformation of hidden layer activation at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer input\n",
      "[[ 0.93469856]\n",
      " [ 0.95233693]\n",
      " [ 0.87994471]]\n",
      "Output\n",
      "[[ 0.71802755]\n",
      " [ 0.72158491]\n",
      " [ 0.70681076]]\n"
     ]
    }
   ],
   "source": [
    "output_layer_input = np.dot(hiddenlayer_activations,wout)+bout\n",
    "\n",
    "print(\"Output layer input\")\n",
    "print(output_layer_input)\n",
    "\n",
    "\n",
    "output = sigmoid(output_layer_input)\n",
    "print(\"Output\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate gradient of Error(E) at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of error\n",
      "[[ 0.28197245]\n",
      " [ 0.27841509]\n",
      " [-0.70681076]]\n"
     ]
    }
   ],
   "source": [
    "E = y-output\n",
    "\n",
    "print(\"Gradient of error\")\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute slope at output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope output layer\n",
      "[[ 0.20246399]\n",
      " [ 0.20090013]\n",
      " [ 0.20722931]]\n",
      "Slope hidden layer\n",
      "[[ 0.12721128  0.08844678  0.10729579]\n",
      " [ 0.0768439   0.08591753  0.09042921]\n",
      " [ 0.2084602   0.14977653  0.1774163 ]]\n"
     ]
    }
   ],
   "source": [
    "Slope_output_layer= sigmoid(output,True)\n",
    "\n",
    "print\"Slope output layer\"\n",
    "print Slope_output_layer\n",
    "\n",
    "Slope_hidden_layer =sigmoid(hiddenlayer_activations,True)\n",
    "print \"Slope hidden layer\"\n",
    "print Slope_hidden_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute delta at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta output\n",
      "[[ 0.00570893]\n",
      " [ 0.00559336]\n",
      " [-0.01464719]]\n"
     ]
    }
   ],
   "source": [
    "d_output = E *Slope_output_layer*lr\n",
    "\n",
    "print \"Delta output\"\n",
    "print d_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Error at hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at hidden layer\n",
      "[[ 0.00521866  0.00546803  0.00194595]\n",
      " [ 0.00511302  0.00535734  0.00190656]\n",
      " [-0.01338933 -0.01402912 -0.00499265]]\n"
     ]
    }
   ],
   "source": [
    "Error_at_hidden_layer = np.dot(d_output,wout.T)\n",
    "print\"Error at hidden layer\"\n",
    "print(Error_at_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute delta at hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta at Hidden layer\n",
      "[[  1.34845554e-03   2.77725576e-05   1.53007450e-03]\n",
      " [  7.98066186e-04   2.64322517e-05   1.26344746e-03]\n",
      " [ -5.66935972e-03  -1.20663935e-04  -6.49117476e-03]]\n"
     ]
    }
   ],
   "source": [
    "d_hiddenlayer = Error_at_hidden_layer * Slope_hidden_layer\n",
    "print \"Delta at Hidden layer\"\n",
    "print(d_hiddenlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update weight at both output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update weight at output layer\n",
      "[[ 0.9141224 ]\n",
      " [ 0.95780265]\n",
      " [ 0.34086078]]\n",
      "Updated weight at hidden layer\n",
      "[[ 0.55822253  0.5370678   0.17528359]\n",
      " [ 0.10776979  0.96626773  0.50466119]\n",
      " [ 0.20350863  0.56020383  0.13144858]\n",
      " [ 0.70830702  0.77844882  0.69990419]]\n"
     ]
    }
   ],
   "source": [
    "wout = wout + np.dot(hiddenlayer_activations.T,d_output)*lr\n",
    "print \"Update weight at output layer\"\n",
    "print(wout)\n",
    "\n",
    "wh = wh+np.dot(x.T,d_hiddenlayer)*lr\n",
    "print \"Updated weight at hidden layer\"\n",
    "print(wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update biases at both output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update bias at hidden layer\n",
      "[[ 0.48286642  0.81463336  0.02844659]]\n",
      "Updated bias at output layer\n",
      "[[ 0.9915749]]\n"
     ]
    }
   ],
   "source": [
    "bh = bh + np.sum(d_hiddenlayer,axis=0)*lr\n",
    "print \"Update bias at hidden layer\"\n",
    "print bh\n",
    "\n",
    "bout = bout + np.sum(d_output,axis=0)*lr\n",
    "print \"Updated bias at output layer\"\n",
    "print bout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
